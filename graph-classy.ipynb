{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "In this notebook, we will explore the process of  classifying graph datasets using **Persistence Signals** vectorization and a Vanilla Random Forest Classifier. The main steps include:\n",
    "\n",
    "1. *Data Generation*: We generate the extended persistence diagrams using HKS and extended persistence from [PersLay](https://arxiv.org/abs/1904.09378).\n",
    "2. *Diagrams Embedding, Model Training, and Evaluation*: We embed the extended diagrams using the Persistence Signals vectorization method. Subsequently, we perform a 10-fold classification using Random Forests and finally evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spectral.utils as spu\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "In this section, we generate the extended persistence diagrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: MUTAG\n",
      "Number of observations: 188\n"
     ]
    }
   ],
   "source": [
    "dataset = \"MUTAG\"\n",
    "filtrations=['0.1-hks', '10.0-hks']\n",
    "spu.compute_extended_persistence(dataset=dataset, filtrations=filtrations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagrams Embedding, Model Training, and Evaluation\n",
    "We train a Vanilla Random Forest Classifier on Persisitence Signals embedding of the extended persistence diagrams. We utilize a 10-fold cross-validation approach to ensure the reliability and generalizability of our model. Finally, we evaluate the performance of our classifier. T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [\"MUTAG\"]\n",
    "algorithms = [\"WAVELET\"]\n",
    "wave_list = [\"coif1\"]\n",
    "grid_list = [(20, 20)]\n",
    "filtrations=[\"0.1-hks\", '10.0-hks']\n",
    "graph_dtypes = [\"dgmOrd0\", \"dgmExt0\", \"dgmRel1\", \"dgmExt1\"]\n",
    "repeat = 1 #Run only one time 10 fold classification\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.97\n",
      "  (Test score) accuracy_score: 0.89\n",
      "Fold 2, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.96\n",
      "  (Test score) accuracy_score: 0.94\n",
      "Fold 3, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.96\n",
      "  (Test score) accuracy_score: 0.89\n",
      "Fold 4, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.97\n",
      "  (Test score) accuracy_score: 0.89\n",
      "Fold 5, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.98\n",
      "  (Test score) accuracy_score: 0.83\n",
      "Fold 6, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.97\n",
      "  (Test score) accuracy_score: 0.89\n",
      "Fold 7, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.96\n",
      "  (Test score) accuracy_score: 0.89\n",
      "Fold 8, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.97\n",
      "  (Test score) accuracy_score: 0.89\n",
      "Fold 9, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.96\n",
      "  (Test score) accuracy_score: 0.89\n",
      "Fold 10, embedding has size: {4608: 170}\n",
      "  (Train score) accuracy_score: 0.96\n",
      "  (Test score) accuracy_score: 0.89\n",
      "DATA: MUTAG, ALG: WAVELET, GRID: (20, 20), MEAN: 0.888888888888889, MAX: 0.888888888888889, STD: 0.0, WAVE: coif1\n"
     ]
    }
   ],
   "source": [
    "for dataset in dataset_list:\n",
    "    graph_folder = os.path.join(\"./data/\", dataset)\n",
    "    all_diags, array_indices = spu.load_and_prepare_data(graph_folder, graph_dtypes, filtrations)\n",
    "    length = len(array_indices) // 10\n",
    "    sampling = \"index\"\n",
    "\n",
    "    for alg in algorithms:\n",
    "        for grid in grid_list:\n",
    "            if alg == \"WAVELET\":\n",
    "                for wave in wave_list:\n",
    "                    spu.evaluate_model(dataset, alg, grid, wave, graph_folder, all_diags, array_indices, length, sampling, graph_dtypes, filtrations, repeat, verbose)\n",
    "            else:\n",
    "                spu.evaluate_model(dataset, alg, grid, None, graph_folder, all_diags, array_indices, length, sampling, graph_dtypes, filtrations, repeat, verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
